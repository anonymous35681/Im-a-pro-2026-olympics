import pandas as pd

# Set pandas options to display all columns if needed
pd.set_option("display.max_columns", None)


def main():
    file_path = "data/origin_dataset.csv"
    try:
        df = pd.read_csv(file_path)
    except Exception as e:
        print(f"Error reading CSV: {e}")
        return

    cols = df.columns

    col_age = cols[5]
    col_edu = cols[6]
    col_marital_status = None
    for col in cols:
        if col.startswith("12. –í–∞—à–µ —Å–µ–º–µ–π–Ω–æ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ"):
            col_marital_status = col
            break
    col_income = cols[13]
    col_city_district = cols[1]
    col_city_name = cols[2]
    col_settlement_type = cols[3]  # 3. –¢–∏–ø –Ω–∞—Å–µ–ª–µ–Ω–Ω–æ–≥–æ –ø—É–Ω–∫—Ç–∞

    trust_map = {
        "–¢–µ–ª–µ–≤–∏–¥–µ–Ω–∏–µ": "[–¢–µ–ª–µ–≤–∏–¥–µ–Ω–∏–µ].1",
        "–ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–°–ú–ò": "[–ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–∏–∑–¥–∞–Ω–∏—è].1",
        "–°–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏": "[–°–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏].1",
        "–î—Ä—É–∑—å—è": "[–î—Ä—É–∑—å—è].1",
        "–ì–∞–∑–µ—Ç—ã": "[–ì–∞–∑–µ—Ç—ã].1",
        "–†–∞–¥–∏–æ": "[–†–∞–¥–∏–æ].1",
    }

    col_general_trust_people = cols[14]
    col_trust_surroundings = cols[15]

    col_freq_perception = cols[48]
    col_encounter_freq = cols[43]
    col_where_seen = [cols[44], cols[45], cols[46], cols[47]]
    col_verify = cols[49]
    col_believed = cols[51]
    col_spread = cols[52]

    report_lines = []
    report_lines.append("# –û—Ç—á–µ—Ç –ø–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—é –¥–∞—Ç–∞—Å–µ—Ç–∞")
    report_lines.append("")

    # --- 1. Trust in Sources ---
    report_lines.append("## - –î–æ–≤–µ—Ä–∏–µ –∫ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")

    total = len(df)

    media_cols = []
    for label, col_name in trust_map.items():
        if col_name in df.columns:
            trust_count = (
                df[col_name]
                .astype(str)
                .apply(lambda x: 1 if "–î–æ–≤–µ—Ä—è—é" in x and "–ù–µ –¥–æ–≤–µ—Ä—è—é" not in x else 0)
                .sum()
            )
            distrust_count = (
                df[col_name]
                .astype(str)
                .apply(lambda x: 1 if "–ù–µ –¥–æ–≤–µ—Ä—è—é" in x else 0)
                .sum()
            )

            trust_pct = (trust_count / total) * 100
            distrust_pct = (distrust_count / total) * 100
            report_lines.append(
                f"- {label}: –î–æ–≤–µ—Ä—è—é—Ç {trust_pct:.1f}%, –ù–µ –¥–æ–≤–µ—Ä—è—é—Ç {distrust_pct:.1f}%"
            )

            # Collect media columns (excluding "–î—Ä—É–∑—å—è")
            if label != "–î—Ä—É–∑—å—è":
                media_cols.append(col_name)
        else:
            report_lines.append(f"- {label}: –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö (–∫–æ–ª–æ–Ω–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞)")

    # Calculate overall trust/distrust - % of people who trust/distrust ANY media source
    if media_cols:
        # Person trusts media if they trust at least one source
        any_trust = (
            df[media_cols]
            .astype(str)
            .apply(
                lambda row: any(
                    "–î–æ–≤–µ—Ä—è—é" in val and "–ù–µ –¥–æ–≤–µ—Ä—è—é" not in val for val in row
                ),
                axis=1,
            )
            .sum()
        )

        # Person distrusts media if they distrust at least one source
        any_distrust = (
            df[media_cols]
            .astype(str)
            .apply(lambda row: any("–ù–µ –¥–æ–≤–µ—Ä—è—é" in val for val in row), axis=1)
            .sum()
        )

        overall_trust_pct = (any_trust / total) * 100
        overall_distrust_pct = (any_distrust / total) * 100
        report_lines.append(
            f"- –û–±—â–µ–µ –ø–æ –≤—Å–µ–º –°–ú–ò: –î–æ–≤–µ—Ä—è—é—Ç {overall_trust_pct:.1f}%, –ù–µ –¥–æ–≤–µ—Ä—è—é—Ç {overall_distrust_pct:.1f}%"
        )

    report_lines.append("")

    # --- 2. Frequency of Fakes (Perception) ---
    report_lines.append("## 2) –ß–∞—Å—Ç–æ—Ç–∞ –ø–æ—è–≤–ª–µ–Ω–∏—è —Ñ–µ–π–∫–æ–≤ (–º–Ω–µ–Ω–∏–µ —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤)")

    if col_freq_perception:
        counts = df[col_freq_perception].value_counts(normalize=True) * 100

        often_sum = 0
        rare_sum = 0
        unsure_sum = 0
        other_sum = 0

        for val, pct in counts.items():
            val_str = str(val).lower()
            match val_str:
                case s if "–∑–∞—Ç—Ä—É–¥–Ω—è—é—Å—å" in s:
                    unsure_sum += pct
                case s if "—Ä–µ–∂–µ" in s:
                    rare_sum += pct
                case s if "—á–∞—â–µ" in s:
                    often_sum += pct
                case _:
                    other_sum += pct

        report_lines.append(f"- –°—á–∏—Ç–∞—é—Ç, —á—Ç–æ —á–∞—Å—Ç–æ (–ß–∞—â–µ): {often_sum:.1f}%")
        report_lines.append(f"- –°—á–∏—Ç–∞—é—Ç, —á—Ç–æ –Ω–µ—á–∞—Å—Ç–æ (–†–µ–∂–µ): {rare_sum:.1f}%")
        report_lines.append(f"- –ó–∞—Ç—Ä—É–¥–Ω–∏–ª–∏—Å—å –æ—Ç–≤–µ—Ç–∏—Ç—å: {unsure_sum:.1f}%")
        if other_sum > 1:
            report_lines.append(f"- –î—Ä—É–≥–æ–µ (–≤ —Ç.—á. '–¢–∞–∫ –∂–µ'): {other_sum:.1f}%")

    report_lines.append("")

    # --- 3. Age 45-65+ vs 18-34 Fake Encounters (with settlement split) ---
    report_lines.append("## 3) –°—Ç–æ–ª–∫–Ω–æ–≤–µ–Ω–∏–µ —Å —Ñ–µ–π–∫–∞–º–∏ –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–º –∏ —Ç–∏–ø—É –ø–æ—Å–µ–ª–µ–Ω–∏—è")

    df["Age_Clean"] = pd.to_numeric(df[col_age], errors="coerce")

    group_older = df[(df["Age_Clean"] >= 45)]
    group_younger = df[(df["Age_Clean"] >= 18) & (df["Age_Clean"] <= 34)]

    def calc_freq_stats(sub_df, label):
        """Calculate frequency stats for a subgroup."""
        total_sub = len(sub_df)
        if total_sub == 0:
            return None

        monthly_plus = (
            sub_df[col_encounter_freq]
            .astype(str)
            .apply(
                lambda x: (
                    1
                    if any(
                        k in x.lower()
                        for k in ["–º–µ—Å—è—Ü", "–Ω–µ–¥–µ–ª—é", "–µ–∂–µ–¥–Ω–µ–≤–Ω–æ", "–∫–∞–∂–¥—ã–π –¥–µ–Ω—å"]
                    )
                    else 0
                )
            )
            .sum()
        )

        daily = (
            sub_df[col_encounter_freq]
            .astype(str)
            .apply(
                lambda x: (
                    1
                    if any(k in x.lower() for k in ["–µ–∂–µ–¥–Ω–µ–≤–Ω–æ", "–∫–∞–∂–¥—ã–π –¥–µ–Ω—å"])
                    else 0
                )
            )
            .sum()
        )

        return f"  - {label}: –ù–µ —Ä–µ–∂–µ –Ω–µ—Å–∫. —Ä–∞–∑ –≤ –º–µ—Å—è—Ü - {(monthly_plus / total_sub) * 100:.1f}%, –ü–æ—á—Ç–∏ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å - {(daily / total_sub) * 100:.1f}%"

    # Process older group (45+)
    report_lines.append("**–õ—é–¥–∏ 45+ –ª–µ—Ç:**")

    # –°–∞—Ä–∞–Ω—Å–∫
    saransk_older = group_older[
        group_older[col_city_district].astype(str).str.contains("–°–∞—Ä–∞–Ω—Å–∫", case=False, na=False)
    ]
    if len(saransk_older) > 0:
        result = calc_freq_stats(saransk_older, "–°–∞—Ä–∞–Ω—Å–∫")
        if result:
            report_lines.append(result)

    # –ì–æ—Ä–æ–¥–∞ –∏ –ø–≥—Ç (–±–µ–∑ –°–∞—Ä–∞–Ω—Å–∫–∞)
    cities_older = group_older[
        group_older[col_settlement_type].astype(str) == "2. –ì–æ—Ä–æ–¥–∞ –∏ –ø–≥—Ç"
    ]
    if len(cities_older) > 0:
        result = calc_freq_stats(cities_older, "–ì–æ—Ä–æ–¥–∞ –∏ –ø–≥—Ç")
        if result:
            report_lines.append(result)

    # –°–µ–ª–∞
    villages_older = group_older[
        group_older[col_settlement_type].astype(str) == "3. –°–µ–ª–∞"
    ]
    if len(villages_older) > 0:
        result = calc_freq_stats(villages_older, "–°–µ–ª–∞")
        if result:
            report_lines.append(result)

    # Process younger group (18-34)
    report_lines.append("**–õ—é–¥–∏ 18-34 –ª–µ—Ç:**")

    # –°–∞—Ä–∞–Ω—Å–∫
    saransk_younger = group_younger[
        group_younger[col_city_district].astype(str).str.contains("–°–∞—Ä–∞–Ω—Å–∫", case=False, na=False)
    ]
    if len(saransk_younger) > 0:
        result = calc_freq_stats(saransk_younger, "–°–∞—Ä–∞–Ω—Å–∫")
        if result:
            report_lines.append(result)

    # –ì–æ—Ä–æ–¥–∞ –∏ –ø–≥—Ç (–±–µ–∑ –°–∞—Ä–∞–Ω—Å–∫–∞)
    cities_younger = group_younger[
        group_younger[col_settlement_type].astype(str) == "2. –ì–æ—Ä–æ–¥–∞ –∏ –ø–≥—Ç"
    ]
    if len(cities_younger) > 0:
        result = calc_freq_stats(cities_younger, "–ì–æ—Ä–æ–¥–∞ –∏ –ø–≥—Ç")
        if result:
            report_lines.append(result)

    # –°–µ–ª–∞
    villages_younger = group_younger[
        group_younger[col_settlement_type].astype(str) == "3. –°–µ–ª–∞"
    ]
    if len(villages_younger) > 0:
        result = calc_freq_stats(villages_younger, "–°–µ–ª–∞")
        if result:
            report_lines.append(result)

    report_lines.append("")

    # --- 4. Believed Fakes ---
    report_lines.append("## 4) –í–µ—Ä–∞ –≤ —Ñ–µ–π–∫–∏")

    counts = df[col_believed].value_counts(normalize=True) * 100

    true_pct = 0
    almost_true_pct = 0

    for val, pct in counts.items():
        val_str = str(val).lower()
        match val_str:
            case s if "–±–µ–∑—É—Å–ª–æ–≤–Ω–æ –¥–∞" in s:
                true_pct += pct
            case s if "—Å–∫–æ—Ä–µ–µ –¥–∞" in s:
                almost_true_pct += pct
            case _:
                pass

    report_lines.append(f"- –ü—Ä–∏–Ω—è–ª–∏ –∑–∞ –ü–†–ê–í–î–£ (–ë–µ–∑—É—Å–ª–æ–≤–Ω–æ –¥–∞): {true_pct:.1f}%")
    report_lines.append(
        f"- –ü—Ä–∏–Ω—è–ª–∏ –∑–∞ –ü–û–ß–¢–ò –ø—Ä–∞–≤–¥—É (–°–∫–æ—Ä–µ–µ –¥–∞): {almost_true_pct:.1f}%"
    )

    report_lines.append("")

    # --- 5. Demographics of 18-34 ---
    report_lines.append("## 5) –ì—Ä—É–ø–ø–∞ —Ä–∏—Å–∫–∞ 18-34")

    group_18_34 = df[(df["Age_Clean"] >= 18) & (df["Age_Clean"] <= 34)]
    total_18_34 = len(group_18_34)

    if total_18_34 > 0:
        believed_counts = (
            group_18_34[col_believed]
            .astype(str)
            .apply(lambda x: 1 if "–¥–∞" in x.lower() else 0)
            .sum()
        )
        believed_pct = (believed_counts / total_18_34) * 100
        report_lines.append(
            f"- 18-34 –ª–µ—Ç: –í–µ—Ä—è—Ç —Ñ–µ–π–∫–∞–º (–ë–µ–∑—É—Å–ª–æ–≤–Ω–æ+–°–∫–æ—Ä–µ–µ –¥–∞): {believed_pct:.1f}%"
        )

        spread_counts = (
            group_18_34[col_spread]
            .astype(str)
            .apply(lambda x: 1 if "–¥–∞" in x.lower() else 0)
            .sum()
        )
        spread_pct = (spread_counts / total_18_34) * 100
        report_lines.append(
            f"- –ê–∫—Ç–∏–≤–Ω–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è—é—Ç (–ü—Ä–∏—Ö–æ–¥–∏–ª–æ—Å—å —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è—Ç—å): {spread_pct:.1f}%"
        )

        with_higher = group_18_34[
            group_18_34[col_edu]
            .astype(str)
            .str.contains("–≤—ã—Å—à–µ–µ", case=False, na=False)
        ]
        without_higher = group_18_34[
            ~group_18_34[col_edu]
            .astype(str)
            .str.contains("–≤—ã—Å—à–µ–µ", case=False, na=False)
        ]

        def get_belief_rate(sub):
            if len(sub) == 0:
                return 0
            return (
                sub[col_believed]
                .astype(str)
                .apply(lambda x: 1 if "–¥–∞" in x.lower() else 0)
                .sum()
                / len(sub)
            ) * 100

        report_lines.append(
            f"- –í–µ—Ä–∞ –≤ —Ñ–µ–π–∫–∏ (—Å –≤—ã—Å—à–∏–º): {get_belief_rate(with_higher):.1f}%"
        )
        report_lines.append(
            f"- –í–µ—Ä–∞ –≤ —Ñ–µ–π–∫–∏ (–±–µ–∑ –≤—ã—Å—à–µ–≥–æ): {get_belief_rate(without_higher):.1f}%"
        )

        v_counts_all = df[col_verify].value_counts(normalize=True) * 100

        pct_opportunity = 0
        pct_sometimes = 0
        pct_never = 0
        pct_hard = 0
        pct_always = 0

        for val, pct in v_counts_all.items():
            val_str = str(val).lower()
            match val_str:
                case s if "–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç" in s:
                    pct_opportunity += pct
                case s if (
                    "–≤—Ä–µ–º—è –æ—Ç –≤—Ä–µ–º–µ–Ω–∏" in s
                    or "–∏–Ω–æ–≥–¥–∞" in s
                    or "–∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Å–∏—Ç—É–∞—Ü–∏–∏" in s
                ):
                    pct_sometimes += pct
                case s if "–Ω–∏–∫–æ–≥–¥–∞" in s:
                    pct_never += pct
                case s if "–∑–∞—Ç—Ä—É–¥–Ω—è—é—Å—å" in s:
                    pct_hard += pct
                case s if "–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ" in s:
                    pct_always += pct
                case _:
                    pass

        report_lines.append(f"- –ñ–∏—Ç–µ–ª–∏ (–í—Å–µ): –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–≤–µ—Ä—è—é—Ç: {pct_always:.1f}%")
        report_lines.append(
            f"- –ñ–∏—Ç–µ–ª–∏ (–í—Å–µ): –ü—Ä–æ–≤–µ—Ä—è—é—Ç –ø–æ –º–µ—Ä–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π: {pct_opportunity:.1f}%"
        )
        report_lines.append(
            f"- –ñ–∏—Ç–µ–ª–∏ (–í—Å–µ): –ü—Ä–æ–≤–µ—Ä—è—é—Ç –≤—Ä–µ–º—è –æ—Ç –≤—Ä–µ–º–µ–Ω–∏: {pct_sometimes:.1f}%"
        )
        report_lines.append(
            f"- –ñ–∏—Ç–µ–ª–∏ (–í—Å–µ): –ü—Ä–∏–Ω—Ü–∏–ø–∏–∞–ª—å–Ω–æ –Ω–µ –ø—Ä–æ–≤–µ—Ä—è—é—Ç: {pct_never:.1f}%"
        )
        report_lines.append(f"- –ñ–∏—Ç–µ–ª–∏ (–í—Å–µ): –ó–∞—Ç—Ä—É–¥–Ω–∏–ª–∏—Å—å –æ—Ç–≤–µ—Ç–∏—Ç—å: {pct_hard:.1f}%")

    report_lines.append("")

    # --- 6. Where Fakes Seen & Risk Groups ---
    report_lines.append("## 6) –ì–¥–µ –≤—Å—Ç—Ä–µ—á–∞–ª–∏ —Ñ–µ–π–∫–∏ –∏ –≥—Ä—É–ø–ø—ã —Ä–∏—Å–∫–∞")

    seen_cols = col_where_seen

    def check_source_seen(row, keyword):
        for c in seen_cols:
            if pd.notna(row[c]) and keyword.lower() in str(row[c]).lower():
                return True
        return False

    seen_socials = df.apply(
        lambda row: check_source_seen(row, "—Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏"), axis=1
    )
    seen_internet = df.apply(lambda row: check_source_seen(row, "–∏–Ω—Ç–µ—Ä–Ω–µ—Ç"), axis=1)
    seen_tv = df.apply(lambda row: check_source_seen(row, "—Ç–µ–ª–µ–≤–∏–¥–µ–Ω–∏–µ"), axis=1)

    report_lines.append(
        f"- –í —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç—è—Ö: {(seen_socials.sum() / total) * 100:.1f}%"
    )
    report_lines.append(f"- –í –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–°–ú–ò: {(seen_internet.sum() / total) * 100:.1f}%")
    report_lines.append(f"- –ù–∞ —Ç–µ–ª–µ–≤–∏–¥–µ–Ω–∏–∏: {(seen_tv.sum() / total) * 100:.1f}%")

    internet_group = df[seen_internet]

    def classify_income(val):
        val_str = str(val).lower()
        match val_str:
            case s if "–µ–¥–≤–∞" in s or "–ø–∏—Ç–∞–Ω–∏–µ" in s:
                return "Low"
            case s if "–æ–¥–µ–∂–¥—É" in s:
                return "Medium"
            case s if "—Ç–µ—Ö–Ω–∏–∫—É" in s or "–∞–≤—Ç–æ" in s or "–Ω–∏ –≤ —á–µ–º" in s:
                return "High"
            case _:
                return "Unknown"

    if len(internet_group) > 0:
        # –°–∞—Ä–∞–Ω—Å–∫
        internet_saransk_pct = (
            internet_group[col_city_district]
            .astype(str)
            .str.contains("–°–∞—Ä–∞–Ω—Å–∫", case=False)
            .sum()
            / len(internet_group)
        ) * 100
        if internet_saransk_pct < 1:
            internet_saransk_pct = (
                internet_group[col_city_name]
                .astype(str)
                .str.contains("–°–∞—Ä–∞–Ω—Å–∫", case=False)
                .sum()
                / len(internet_group)
            ) * 100

        # –î—Ä—É–≥–∏–µ –≥–æ—Ä–æ–¥–∞ –∏ –ø–≥—Ç
        internet_other_cities_pct = (
            internet_group[col_settlement_type]
            .astype(str)
            .str.contains("2. –ì–æ—Ä–æ–¥–∞ –∏ –ø–≥—Ç", case=False)
            .sum()
            / len(internet_group)
        ) * 100

        # –°–µ–ª–∞
        internet_villages_pct = (
            internet_group[col_settlement_type]
            .astype(str)
            .str.contains("3. –°–µ–ª–∞", case=False)
            .sum()
            / len(internet_group)
        ) * 100

        # –î–æ—Ö–æ–¥
        internet_income_counts = (
            internet_group[col_income]
            .apply(classify_income)
            .value_counts(normalize=True)
            * 100
        )

        report_lines.append(
            f"- –ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–∏–∑–¥–∞–Ω–∏—è (–∞—É–¥–∏—Ç–æ—Ä–∏—è): "
            f"–°–∞—Ä–∞–Ω—Å–∫ {internet_saransk_pct:.1f}%, "
            f"–ì–æ—Ä–æ–¥–∞ –∏ –ø–≥—Ç {internet_other_cities_pct:.1f}%, "
            f"–°–µ–ª–∞ {internet_villages_pct:.1f}%; "
            f"–î–æ—Ö–æ–¥ —Å—Ä–µ–¥–Ω–∏–π/–≤—ã—Å–æ–∫–∏–π {(internet_income_counts.get('Medium', 0) + internet_income_counts.get('High', 0)):.1f}%"
        )

    tv_skeptics = df[
        df["[–¢–µ–ª–µ–≤–∏–¥–µ–Ω–∏–µ].1"]
        .astype(str)
        .str.contains("–ù–µ –¥–æ–≤–µ—Ä—è—é", case=False, na=False)
    ]

    if len(tv_skeptics) > 0:
        pct_18_24 = (
            tv_skeptics[
                (tv_skeptics["Age_Clean"] >= 18) & (tv_skeptics["Age_Clean"] <= 24)
            ].shape[0]
            / len(tv_skeptics)
        ) * 100

        pct_saransk = (
            tv_skeptics[col_city_district]
            .astype(str)
            .str.contains("–°–∞—Ä–∞–Ω—Å–∫", case=False)
            .sum()
            / len(tv_skeptics)
        ) * 100
        if pct_saransk < 1:
            pct_saransk = (
                tv_skeptics[col_city_name]
                .astype(str)
                .str.contains("–°–∞—Ä–∞–Ω—Å–∫", case=False)
                .sum()
                / len(tv_skeptics)
            ) * 100

        pct_high_income = (
            tv_skeptics[col_income].apply(classify_income).isin(["High"]).sum()
            / len(tv_skeptics)
        ) * 100

        report_lines.append(
            f"- –°–∫–µ–ø—Ç–∏–∫–∏ –¢–í: 18-24 –ª–µ—Ç {pct_18_24:.1f}%, –°–∞—Ä–∞–Ω—Å–∫ {pct_saransk:.1f}%, –í—ã—Å–æ–∫–∏–π –¥–æ—Ö–æ–¥ {pct_high_income:.1f}%"
        )

    # Check for fakes in conversations with friends/relatives
    seen_friends_count = 0
    for col in seen_cols:
        seen_friends_count += (
            df[col]
            .astype(str)
            .str.contains("–î—Ä—É–∑—å—è, —Ä–æ–¥–Ω—ã–µ, –∑–Ω–∞–∫–æ–º—ã–µ", case=False, na=False)
            .sum()
        )
    seen_friends_pct = (seen_friends_count / total) * 100
    report_lines.append(
        f"- –°—Ç–∞–ª–∫–∏–≤–∞–ª–∏—Å—å —Å —Ñ–µ–π–∫–∞–º–∏ –≤ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞—Ö —Å –¥—Ä—É–∑—å—è–º–∏/—Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–∏–∫–∞–º–∏: {seen_friends_pct:.1f}%"
    )

    trust_close_circle_col = col_trust_surroundings
    if trust_close_circle_col in df.columns:
        trust_close_circle_pct = (
            df[trust_close_circle_col]
            .astype(str)
            .str.contains("–ë–æ–ª—å—à–∏–Ω—Å—Ç–≤—É –ª—é–¥–µ–π –º–æ–∂–Ω–æ –¥–æ–≤–µ—Ä—è—Ç—å", case=False)
            .sum()
            / total
        ) * 100
        report_lines.append(
            f"- –î–æ–≤–µ—Ä—è—é—Ç —Å–≤–æ–∏–º —Ä–æ–¥–Ω—ã–º –∏ –±–ª–∏–∑–∫–∏–º (Q15): {trust_close_circle_pct:.1f}%"
        )

    if col_general_trust_people in df.columns:
        general_trust_pct = (
            df[col_general_trust_people]
            .astype(str)
            .str.contains("–ë–æ–ª—å—à–∏–Ω—Å—Ç–≤—É –ª—é–¥–µ–π –º–æ–∂–Ω–æ –¥–æ–≤–µ—Ä—è—Ç—å", case=False)
            .sum()
            / total
        ) * 100
        report_lines.append(
            f"- –û–±—â–∏–π –∏–Ω–¥–µ–∫—Å –¥–æ–≤–µ—Ä–∏—è –∫ –ª—é–¥—è–º (Q14): {general_trust_pct:.1f}%"
        )

    # --- 7. Trust in TV by Age, Income, and Marital Status (split by Settlement) ---
    report_lines.append("## 7) –î–æ–≤–µ—Ä–∏–µ –∫ —Ç–µ–ª–µ–≤–∏–¥–µ–Ω–∏—é –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–æ–∑—Ä–∞—Å—Ç–∞, –¥–æ—Ö–æ–¥–∞ –∏ —Å–µ–º–µ–π–Ω–æ–≥–æ –ø–æ–ª–æ–∂–µ–Ω–∏—è (—Å —Ä–∞–∑–±–∏–≤–∫–æ–π –Ω–∞ —Å–µ–ª–∞/–≥–æ—Ä–æ–¥–∞)")

    tv_col = "[–¢–µ–ª–µ–≤–∏–¥–µ–Ω–∏–µ].1"
    if tv_col not in df.columns:
        report_lines.append("–î–∞–Ω–Ω—ã–µ –æ –¥–æ–≤–µ—Ä–∏–∏ –∫ –¢–í –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")
    else:
        # Age groups
        df["Age_Clean"] = pd.to_numeric(df[col_age], errors="coerce")

        # Settlement types
        settlement_map = {
            "1. –°–∞—Ä–∞–Ω—Å–∫": "city",
            "2. –ì–æ—Ä–æ–¥–∞ –∏ –ø–≥—Ç": "city",
            "3. –°–µ–ª–∞": "village",
        }
        df["Settlement_Type"] = df[col_settlement_type].map(settlement_map)

        age_groups = [
            ("18-24", (df["Age_Clean"] >= 18) & (df["Age_Clean"] <= 24)),
            ("25-34", (df["Age_Clean"] >= 25) & (df["Age_Clean"] <= 34)),
            ("35-44", (df["Age_Clean"] >= 35) & (df["Age_Clean"] <= 44)),
            ("45-54", (df["Age_Clean"] >= 45) & (df["Age_Clean"] <= 54)),
            ("55-64", (df["Age_Clean"] >= 55) & (df["Age_Clean"] <= 64)),
            ("65+", (df["Age_Clean"] >= 65)),
        ]

        report_lines.append("**–ü–æ –≤–æ–∑—Ä–∞—Å—Ç–Ω—ã–º –≥—Ä—É–ø–ø–∞–º (–≥–æ—Ä–æ–¥–∞ vs —Å–µ–ª–∞):**")

        for age_label, age_mask in age_groups:
            age_df = df[age_mask]
            if len(age_df) == 0:
                continue

            report_lines.append(f"- {age_label} –ª–µ—Ç:")

            for settlement_type, settlement_name in [("city", "–ì–æ—Ä–æ–¥–∞"), ("village", "–°–µ–ª–∞")]:
                settle_df = age_df[age_df["Settlement_Type"] == settlement_type]

                if len(settle_df) == 0:
                    continue

                trust_count = (
                    settle_df[tv_col]
                    .astype(str)
                    .apply(lambda x: 1 if "–î–æ–≤–µ—Ä—è—é" in x and "–ù–µ –¥–æ–≤–µ—Ä—è—é" not in x else 0)
                    .sum()
                )

                distrust_count = (
                    settle_df[tv_col]
                    .astype(str)
                    .apply(lambda x: 1 if "–ù–µ –¥–æ–≤–µ—Ä—è—é" in x else 0)
                    .sum()
                )

                trust_pct = (trust_count / len(settle_df)) * 100
                distrust_pct = (distrust_count / len(settle_df)) * 100

                report_lines.append(
                    f"  - {settlement_name}: –î–æ–≤–µ—Ä—è—é—Ç {trust_pct:.1f}%, –ù–µ –¥–æ–≤–µ—Ä—è—é—Ç {distrust_pct:.1f}%"
                )

        report_lines.append("")
        report_lines.append("**–ü–æ —É—Ä–æ–≤–Ω—é –¥–æ—Ö–æ–¥–∞ (–≥–æ—Ä–æ–¥–∞ vs —Å–µ–ª–∞):**")

        for income_level in ["Low", "Medium", "High"]:
            income_df = df[df[col_income].apply(classify_income) == income_level]

            if len(income_df) == 0:
                continue

            income_labels = {"Low": "–ù–∏–∑–∫–∏–π", "Medium": "–°—Ä–µ–¥–Ω–∏–π", "High": "–í—ã—Å–æ–∫–∏–π"}
            report_lines.append(f"- {income_labels[income_level]} –¥–æ—Ö–æ–¥:")

            for settlement_type, settlement_name in [("city", "–ì–æ—Ä–æ–¥–∞"), ("village", "–°–µ–ª–∞")]:
                settle_df = income_df[income_df["Settlement_Type"] == settlement_type]

                if len(settle_df) == 0:
                    continue

                trust_count = (
                    settle_df[tv_col]
                    .astype(str)
                    .apply(lambda x: 1 if "–î–æ–≤–µ—Ä—è—é" in x and "–ù–µ –¥–æ–≤–µ—Ä—è—é" not in x else 0)
                    .sum()
                )

                distrust_count = (
                    settle_df[tv_col]
                    .astype(str)
                    .apply(lambda x: 1 if "–ù–µ –¥–æ–≤–µ—Ä—è—é" in x else 0)
                    .sum()
                )

                trust_pct = (trust_count / len(settle_df)) * 100
                distrust_pct = (distrust_count / len(settle_df)) * 100

                report_lines.append(
                    f"  - {settlement_name}: –î–æ–≤–µ—Ä—è—é—Ç {trust_pct:.1f}%, –ù–µ –¥–æ–≤–µ—Ä—è—é—Ç {distrust_pct:.1f}%"
                )

        report_lines.append("")
        report_lines.append("**–ü–æ —Å–µ–º–µ–π–Ω–æ–º—É –ø–æ–ª–æ–∂–µ–Ω–∏—é (–≥–æ—Ä–æ–¥–∞ vs —Å–µ–ª–∞):**")

        # Get unique marital status values
        if col_marital_status is not None:
            marital_statuses = df[col_marital_status].dropna().unique()

            for status in sorted(marital_statuses):
                status_df = df[df[col_marital_status] == status]

                if len(status_df) == 0:
                    continue

                report_lines.append(f"- {status}:")

                for settlement_type, settlement_name in [("city", "–ì–æ—Ä–æ–¥–∞"), ("village", "–°–µ–ª–∞")]:
                    settle_df = status_df[status_df["Settlement_Type"] == settlement_type]

                    if len(settle_df) == 0:
                        continue

                    trust_count = (
                        settle_df[tv_col]
                        .astype(str)
                        .apply(lambda x: 1 if "–î–æ–≤–µ—Ä—è—é" in x and "–ù–µ –¥–æ–≤–µ—Ä—è—é" not in x else 0)
                        .sum()
                    )

                    distrust_count = (
                        settle_df[tv_col]
                        .astype(str)
                        .apply(lambda x: 1 if "–ù–µ –¥–æ–≤–µ—Ä—è—é" in x else 0)
                        .sum()
                    )

                    trust_pct = (trust_count / len(settle_df)) * 100
                    distrust_pct = (distrust_count / len(settle_df)) * 100

                    report_lines.append(
                        f"  - {settlement_name}: –î–æ–≤–µ—Ä—è—é—Ç {trust_pct:.1f}%, –ù–µ –¥–æ–≤–µ—Ä—è—é—Ç {distrust_pct:.1f}%"
                    )
        else:
            report_lines.append("- –î–∞–Ω–Ω—ã–µ –æ —Å–µ–º–µ–π–Ω–æ–º –ø–æ–ª–æ–∂–µ–Ω–∏–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")

    report_lines.append("")

    # --- 8. Family and Education by TV Watching (Focus on 44-64) ---
    report_lines.append("## 8) –°–µ–º—å—è –∏ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¢–í")

    # TV trust vs no trust
    tv_trust_df = df[
        df["[–¢–µ–ª–µ–≤–∏–¥–µ–Ω–∏–µ].1"]
        .astype(str)
        .str.contains("–î–æ–≤–µ—Ä—è—é", case=False, na=False)
        & ~df["[–¢–µ–ª–µ–≤–∏–¥–µ–Ω–∏–µ].1"]
        .astype(str)
        .str.contains("–ù–µ –¥–æ–≤–µ—Ä—è—é", case=False, na=False)
    ]

    tv_distrust_df = df[
        df["[–¢–µ–ª–µ–≤–∏–¥–µ–Ω–∏–µ].1"]
        .astype(str)
        .str.contains("–ù–µ –¥–æ–≤–µ—Ä—è—é", case=False, na=False)
    ]

    # Overall analysis
    report_lines.append("### –í—Å–µ –≤–æ–∑—Ä–∞—Å—Ç—ã")
    report_lines.append("**–î–æ–≤–µ—Ä—è—é—Ç –¢–í:**")

    if len(tv_trust_df) > 0:
        # Family trust among TV trusters
        family_trust_pct = (
            tv_trust_df[col_trust_surroundings]
            .astype(str)
            .str.contains("–ë–æ–ª—å—à–∏–Ω—Å—Ç–≤—É –ª—é–¥–µ–π –º–æ–∂–Ω–æ –¥–æ–≤–µ—Ä—è—Ç—å", case=False)
            .sum()
            / len(tv_trust_df)
        ) * 100
        report_lines.append(f"- –î–æ–≤–µ—Ä—è—é—Ç —Å–µ–º—å–µ –∏ –±–ª–∏–∑–∫–∏–º: {family_trust_pct:.1f}%")

        # Education distribution
        higher_edu_pct = (
            tv_trust_df[col_edu]
            .astype(str)
            .str.contains("–≤—ã—Å—à–µ–µ", case=False, na=False)
            .sum()
            / len(tv_trust_df)
        ) * 100
        report_lines.append(f"- –° –≤—ã—Å—à–∏–º –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º: {higher_edu_pct:.1f}%")

    report_lines.append("**–ù–µ –¥–æ–≤–µ—Ä—è—é—Ç –¢–í:**")

    if len(tv_distrust_df) > 0:
        # Family trust among TV distrusters
        family_trust_pct = (
            tv_distrust_df[col_trust_surroundings]
            .astype(str)
            .str.contains("–ë–æ–ª—å—à–∏–Ω—Å—Ç–≤—É –ª—é–¥–µ–π –º–æ–∂–Ω–æ –¥–æ–≤–µ—Ä—è—Ç—å", case=False)
            .sum()
            / len(tv_distrust_df)
        ) * 100
        report_lines.append(f"- –î–æ–≤–µ—Ä—è—é—Ç —Å–µ–º—å–µ –∏ –±–ª–∏–∑–∫–∏–º: {family_trust_pct:.1f}%")

        # Education distribution
        higher_edu_pct = (
            tv_distrust_df[col_edu]
            .astype(str)
            .str.contains("–≤—ã—Å—à–µ–µ", case=False, na=False)
            .sum()
            / len(tv_distrust_df)
        ) * 100
        report_lines.append(f"- –° –≤—ã—Å—à–∏–º –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º: {higher_edu_pct:.1f}%")

    # Focus on 44-64 age group
    report_lines.append("")
    report_lines.append("### üîç –í–û–ó–†–ê–°–¢–ù–ê–Ø –ì–†–£–ü–ü–ê 44-64 –ì–û–î–ê (–ê–∫—Ü–µ–Ω—Ç –≤–Ω–∏–º–∞–Ω–∏—è)")

    age_44_64_df = df[(df["Age_Clean"] >= 44) & (df["Age_Clean"] <= 64)]

    if len(age_44_64_df) > 0:
        report_lines.append(f"**–í—Å–µ–≥–æ —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤ 44-64 –ª–µ—Ç: {len(age_44_64_df)}**")
        report_lines.append("")

        # TV trusters 44-64
        tv_trust_44_64 = age_44_64_df[
            age_44_64_df["[–¢–µ–ª–µ–≤–∏–¥–µ–Ω–∏–µ].1"]
            .astype(str)
            .str.contains("–î–æ–≤–µ—Ä—è—é", case=False, na=False)
            & ~age_44_64_df["[–¢–µ–ª–µ–≤–∏–¥–µ–Ω–∏–µ].1"]
            .astype(str)
            .str.contains("–ù–µ –¥–æ–≤–µ—Ä—è—é", case=False, na=False)
        ]

        # TV distrusters 44-64
        tv_distrust_44_64 = age_44_64_df[
            age_44_64_df["[–¢–µ–ª–µ–≤–∏–¥–µ–Ω–∏–µ].1"]
            .astype(str)
            .str.contains("–ù–µ –¥–æ–≤–µ—Ä—è—é", case=False, na=False)
        ]

        report_lines.append("**–î–æ–≤–µ—Ä—è—é—Ç –¢–í (44-64 –≥–æ–¥–∞):**")

        if len(tv_trust_44_64) > 0:
            pct_of_group = (len(tv_trust_44_64) / len(age_44_64_df)) * 100
            report_lines.append(f"- –î–æ–ª—è –æ—Ç –≥—Ä—É–ø–ø—ã 44-64: {pct_of_group:.1f}%")

            # Family trust
            family_trust_pct = (
                tv_trust_44_64[col_trust_surroundings]
                .astype(str)
                .str.contains("–ë–æ–ª—å—à–∏–Ω—Å—Ç–≤—É –ª—é–¥–µ–π –º–æ–∂–Ω–æ –¥–æ–≤–µ—Ä—è—Ç—å", case=False)
                .sum()
                / len(tv_trust_44_64)
            ) * 100
            report_lines.append(f"- –î–æ–≤–µ—Ä—è—é—Ç —Å–µ–º—å–µ –∏ –±–ª–∏–∑–∫–∏–º: {family_trust_pct:.1f}%")

            # Education breakdown
            higher_edu_pct = (
                tv_trust_44_64[col_edu]
                .astype(str)
                .str.contains("–≤—ã—Å—à–µ–µ", case=False, na=False)
                .sum()
                / len(tv_trust_44_64)
            ) * 100
            report_lines.append(f"- –° –≤—ã—Å—à–∏–º –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º: {higher_edu_pct:.1f}%")

            secondary_edu_pct = (
                tv_trust_44_64[col_edu]
                .astype(str)
                .str.contains("—Å—Ä–µ–¥–Ω–µ–µ", case=False, na=False)
                .sum()
                / len(tv_trust_44_64)
            ) * 100
            report_lines.append(f"- –°–æ —Å—Ä–µ–¥–Ω–∏–º –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º: {secondary_edu_pct:.1f}%")

            # Income distribution
            income_dist = (
                tv_trust_44_64[col_income]
                .apply(classify_income)
                .value_counts(normalize=True)
                * 100
            )
            report_lines.append("- –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–æ—Ö–æ–¥—É:")
            for income_level in ["Low", "Medium", "High"]:
                if income_level in income_dist:
                    income_labels = {"Low": "–ù–∏–∑–∫–∏–π", "Medium": "–°—Ä–µ–¥–Ω–∏–π", "High": "–í—ã—Å–æ–∫–∏–π"}
                    report_lines.append(
                        f"  - {income_labels[income_level]}: {income_dist[income_level]:.1f}%"
                    )

        report_lines.append("")
        report_lines.append("**–ù–µ –¥–æ–≤–µ—Ä—è—é—Ç –¢–í (44-64 –≥–æ–¥–∞):**")

        if len(tv_distrust_44_64) > 0:
            pct_of_group = (len(tv_distrust_44_64) / len(age_44_64_df)) * 100
            report_lines.append(f"- –î–æ–ª—è –æ—Ç –≥—Ä—É–ø–ø—ã 44-64: {pct_of_group:.1f}%")

            # Family trust
            family_trust_pct = (
                tv_distrust_44_64[col_trust_surroundings]
                .astype(str)
                .str.contains("–ë–æ–ª—å—à–∏–Ω—Å—Ç–≤—É –ª—é–¥–µ–π –º–æ–∂–Ω–æ –¥–æ–≤–µ—Ä—è—Ç—å", case=False)
                .sum()
                / len(tv_distrust_44_64)
            ) * 100
            report_lines.append(f"- –î–æ–≤–µ—Ä—è—é—Ç —Å–µ–º—å–µ –∏ –±–ª–∏–∑–∫–∏–º: {family_trust_pct:.1f}%")

            # Education breakdown
            higher_edu_pct = (
                tv_distrust_44_64[col_edu]
                .astype(str)
                .str.contains("–≤—ã—Å—à–µ–µ", case=False, na=False)
                .sum()
                / len(tv_distrust_44_64)
            ) * 100
            report_lines.append(f"- –° –≤—ã—Å—à–∏–º –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º: {higher_edu_pct:.1f}%")

            secondary_edu_pct = (
                tv_distrust_44_64[col_edu]
                .astype(str)
                .str.contains("—Å—Ä–µ–¥–Ω–µ–µ", case=False, na=False)
                .sum()
                / len(tv_distrust_44_64)
            ) * 100
            report_lines.append(f"- –°–æ —Å—Ä–µ–¥–Ω–∏–º –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º: {secondary_edu_pct:.1f}%")

            # Income distribution
            income_dist = (
                tv_distrust_44_64[col_income]
                .apply(classify_income)
                .value_counts(normalize=True)
                * 100
            )
            report_lines.append("- –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–æ—Ö–æ–¥—É:")
            for income_level in ["Low", "Medium", "High"]:
                if income_level in income_dist:
                    income_labels = {"Low": "–ù–∏–∑–∫–∏–π", "Medium": "–°—Ä–µ–¥–Ω–∏–π", "High": "–í—ã—Å–æ–∫–∏–π"}
                    report_lines.append(
                        f"  - {income_labels[income_level]}: {income_dist[income_level]:.1f}%"
                    )

        report_lines.append("")
        report_lines.append("**–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (44-64 –≥–æ–¥–∞):**")

        if len(tv_trust_44_64) > 0 and len(tv_distrust_44_64) > 0:
            # Compare family trust
            trust_family = (
                tv_trust_44_64[col_trust_surroundings]
                .astype(str)
                .str.contains("–ë–æ–ª—å—à–∏–Ω—Å—Ç–≤—É –ª—é–¥–µ–π –º–æ–∂–Ω–æ –¥–æ–≤–µ—Ä—è—Ç—å", case=False)
                .sum()
                / len(tv_trust_44_64)
            ) * 100

            distrust_family = (
                tv_distrust_44_64[col_trust_surroundings]
                .astype(str)
                .str.contains("–ë–æ–ª—å—à–∏–Ω—Å—Ç–≤—É –ª—é–¥–µ–π –º–æ–∂–Ω–æ –¥–æ–≤–µ—Ä—è—Ç—å", case=False)
                .sum()
                / len(tv_distrust_44_64)
            ) * 100

            diff_family = trust_family - distrust_family
            report_lines.append(
                f"- –†–∞–∑–Ω–∏—Ü–∞ –≤ –¥–æ–≤–µ—Ä–∏–∏ —Å–µ–º—å–µ: {diff_family:+.1f}% –ø.–ø. (–î–æ–≤–µ—Ä—è—é—â–∏–µ –¢–í {'–±–æ–ª—å—à–µ' if diff_family > 0 else '–º–µ–Ω—å—à–µ'} –¥–æ–≤–µ—Ä—è—é—Ç —Å–µ–º—å–µ)"
            )

            # Compare higher education
            trust_edu = (
                tv_trust_44_64[col_edu]
                .astype(str)
                .str.contains("–≤—ã—Å—à–µ–µ", case=False, na=False)
                .sum()
                / len(tv_trust_44_64)
            ) * 100

            distrust_edu = (
                tv_distrust_44_64[col_edu]
                .astype(str)
                .str.contains("–≤—ã—Å—à–µ–µ", case=False, na=False)
                .sum()
                / len(tv_distrust_44_64)
            ) * 100

            diff_edu = trust_edu - distrust_edu
            report_lines.append(
                f"- –†–∞–∑–Ω–∏—Ü–∞ –≤ –≤—ã—Å—à–µ–º –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏: {diff_edu:+.1f}% –ø.–ø. ({'–î–æ–≤–µ—Ä—è—é—â–∏–µ' if diff_edu > 0 else '–ù–µ –¥–æ–≤–µ—Ä—è—é—â–∏–µ'} –¢–í —á–∞—â–µ –∏–º–µ—é—Ç –≤—ã—Å—à–µ–µ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ)"
            )

            # Compare income
            trust_high_income = (
                tv_trust_44_64[col_income]
                .apply(classify_income)
                .isin(["High"])
                .sum()
                / len(tv_trust_44_64)
            ) * 100

            distrust_high_income = (
                tv_distrust_44_64[col_income]
                .apply(classify_income)
                .isin(["High"])
                .sum()
                / len(tv_distrust_44_64)
            ) * 100

            diff_income = trust_high_income - distrust_high_income
            report_lines.append(
                f"- –†–∞–∑–Ω–∏—Ü–∞ –≤ –≤—ã—Å–æ–∫–æ–º –¥–æ—Ö–æ–¥–µ: {diff_income:+.1f}% –ø.–ø. ({'–î–æ–≤–µ—Ä—è—é—â–∏–µ' if diff_income > 0 else '–ù–µ –¥–æ–≤–µ—Ä—è—é—â–∏–µ'} –¢–í —á–∞—â–µ –∏–º–µ—é—Ç –≤—ã—Å–æ–∫–∏–π –¥–æ—Ö–æ–¥)"
            )

    report_lines.append("")

    with open("report.md", "w") as f:
        f.write("\n".join(report_lines))

    print("Analysis complete. Report saved to ./report.md")


if __name__ == "__main__":
    main()
